{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## context for may 15 session\n",
    "\n",
    "- we find it a little difficult to find datasets when we need them, so we want to build a tool to fix this\n",
    "- we want smart search on dataset descriptions\n",
    "- \"smart\" part of smart search will come from AI\n",
    "- last class we used AI in a very rudimentary way - and it seemed to do what we need it to do. \n",
    "- however the approach we took does not scale (we can't copy paste ALL dataset descriptions into the context window of GPT 4 every time we want it to find us a dataset)\n",
    "\n",
    "### the \"real\" approach\n",
    "\n",
    "- we're going to use embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "import openai\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "import os\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-small\"): # \n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    response = openai.Embedding.create(input=[text], model=model)\n",
    "\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/arad/repos/pp_kaggle_query/csvs/DatasetVersions.csv')\n",
    "df = df.loc[~df['Description'].isna(),:].sample(100)\n",
    "df = df[['DatasetId','Description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_encoding = \"cl100k_base\"\n",
    "max_tokens = 8000 # technically max_tokens is 8191?\n",
    "encoding = tiktoken.get_encoding(embedding_encoding)\n",
    "# if too long remove description - we know we have a few VERY long ones (unlikely to be in this sample)\n",
    "df[\"n_tokens\"] = df['Description'].apply(lambda x: len(encoding.encode(x)))\n",
    "df = df[df.n_tokens <= max_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"embedding\"] = df['Description'].apply(lambda x: get_embedding(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vector = np.zeros([1536])\n",
    "dataset_vector = np.array(df.iloc[6,:]['embedding'])\n",
    "np.linalg.norm(dataset_vector - test_vector)\n",
    "\n",
    "# the above was just one distance calculation\n",
    "# when we compare the user query to the datasets, we need to do many calculations\n",
    "# use the apply method for dataframes\n",
    "\n",
    "df['distance'] = df['embedding'].apply(lambda x: np.linalg.norm(x - test_vector))\n",
    "df['distance'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_query(user_query,dataset_embeddings):\n",
    "\n",
    "    user_embedding = get_embedding(user_query)\n",
    "    # user embedding and descr embeddings can't both be lists\n",
    "    user_embedding = np.array(user_embedding)\n",
    "\n",
    "    # take the distance between user_embedding and all dataset embeddings - dist = numpy.linalg.norm(a-b)\n",
    "\n",
    "    dataset_embeddings['distance'] = df['embedding'].apply(lambda x: np.linalg.norm(x - user_embedding))\n",
    "\n",
    "    dataset_embeddings.sort_values(by='distance', ascending=True, inplace=True)\n",
    "\n",
    "    return df.iloc[0:5,:]['DatasetId'].values\n",
    "\n",
    "def get_dataset_info(top_5_datasets_array,dataset_df):\n",
    "\n",
    "    subset_df = dataset_df.loc[dataset_df['DatasetId'].isin(top_5_datasets_array),[\"Title\",\"Subtitle\",\"Description\"]]\n",
    "\n",
    "    for index, row in subset_df.iterrows():\n",
    "        print(row['Title'])\n",
    "        print(row[\"Subtitle\"])\n",
    "        print(\"*\"*100)\n",
    "        print(\"\\n\")\n",
    "        print(\"Dataset Description:\\n\")\n",
    "        print(row['Description'])\n",
    "        \n",
    "test_query = \"i am really interested in doing an analysis on indian crop yields.\"\n",
    "\n",
    "test_array = process_user_query(test_query,df)\n",
    "\n",
    "#get_dataset_info(test_array,df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which dataset descriptions are not worthy of being embedded?\n",
    "df_full = pd.read_csv('/Users/arad/repos/pp_kaggle_query/csvs/DatasetVersions.csv')\n",
    "df_full.info()\n",
    "# how much will cost to embed the worthy ones (we'll worry about this later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.dropna(inplace = True)\n",
    "df_full.duplicated(subset=['DatasetId']).sum()\n",
    "print(df_full['DatasetId'].nunique())\n",
    "df_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deduplicate by datasetid, taking most recent\n",
    "df_full[\"CreationDate\"] = pd.to_datetime(df_full[\"CreationDate\"]) # CreationDate::date\n",
    "df_full.sort_values(by = \"CreationDate\",ascending=False,inplace=True)\n",
    "df_full.drop_duplicates(subset = [\"DatasetId\"],keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1077"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# duplicate descriptions\n",
    "df_full.duplicated(subset=['Description']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is user id 6047420\n",
    "# guillemservera?\n",
    "users = pd.read_csv('/Users/arad/repos/pp_kaggle_query/csvs/Users.csv')\n",
    "users.loc[users['Id'] == 6047420,:] # yes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['char_count'] = df_full['Description'].apply(len)\n",
    "df_full['char_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closer inspection - these all seem to be junk\n",
    "df_full.loc[df_full['char_count'] < 10,:].sort_values(by = 'char_count',ascending=False).to_csv('short_descriptions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
