{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"/Users/arad/repos/pp_kaggle_query/db\")\n",
    "collection = client.get_collection(name=\"kaggle\")\n",
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query_collection = client.get_collection(name=\"user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query_collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "import os\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "openai.api_key = api_key\n",
    "\n",
    "# from oai via chroma\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key=api_key,\n",
    "                model_name=\"text-embedding-3-small\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create user query collection\n",
    "user_query_collection = client.get_or_create_collection(name=\"user\",\n",
    "    embedding_function=openai_ef, metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b3107436-5925-425a-9195-3e335513c7c1\n",
      "1427359681\n"
     ]
    }
   ],
   "source": [
    "# import uuid\n",
    "\n",
    "# # generate a random uuid\n",
    "# random_uuid = uuid.uuid4().int & (1<<32)-1\n",
    "\n",
    "# # convert the uuid to a 32-bit integer\n",
    "# random_id = random_uuid.int & (1<<32)-1\n",
    "# print(random_uuid)\n",
    "# print(random_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# collection.get(ids=['3607951', '3625760', '3636497', '3639234'],include=['embeddings','metadatas'])\n",
    "\n",
    "# we need to make another \"collection\" for user queries\n",
    "# when a user writes a query\n",
    "## we add it to the user query collection (this will automatically embed it)\n",
    "## we get the user query embedding out of that collection\n",
    "## and pass it to the query function on the dataset description collection.\n",
    "\n",
    "\n",
    "# request = \"I am looking for data on Indian crop yields\"\n",
    "\n",
    "# creating a query_id\n",
    "# embedding/vectorizing the user query\n",
    "# finding similar datasets\n",
    "# replying to the user is a third thing\n",
    "\n",
    "def assign_query_id():\n",
    "    import uuid\n",
    "    return uuid.uuid4().int & (1<<32)-1\n",
    "\n",
    "def embed_user_query(query):\n",
    "    query_id = assign_query_id()\n",
    "    user_query_collection.add(ids=[str(query_id)], documents=[query])\n",
    "    query_embedding = user_query_collection.get(ids=[str(query_id)],include=[\"embeddings\"])['embeddings']\n",
    "    \n",
    "    return query_embedding\n",
    "\n",
    "def find_datasets(query_embedding):\n",
    "\n",
    "    query_response = \\\n",
    "    collection.query(\n",
    "    query_embeddings=query_embedding,\n",
    "    n_results=5\n",
    "    )\n",
    "\n",
    "    metadata = query_response['metadatas'][0]\n",
    "    descriptions = query_response['documents'][0]\n",
    "    \n",
    "    return descriptions, metadata\n",
    "\n",
    "def reply_to_user(metadata):\n",
    "    \n",
    "    metadata_df = pd.DataFrame(metadata).sort_values('TotalDownloads',ascending=False).reset_index(drop = True)\n",
    "\n",
    "    print(\"here's what I found:\\n\")\n",
    "    for index,row in metadata_df.iterrows():    \n",
    "        print(f\"{index + 1}. {row['Title']}{row['Subtitle']} -- total downloads: {row['TotalDownloads']}\")\n",
    "\n",
    "    print(\"\\ninterested in any of these?\")\n",
    "\n",
    "\n",
    "def interface(query):\n",
    "    embedding = embed_user_query(query)\n",
    "    _, metadata = find_datasets(embedding)\n",
    "    reply = reply_to_user(metadata)\n",
    "    print(reply)\n",
    "    return reply\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here's what I found:\n",
      "\n",
      "1. NHL DataPlayer, team, and shots data from 2008-2023 -- total downloads: 181\n",
      "2. NHL Player and Team Data 2008/9-2021/22Data originated with moneypuck.com and hockey-reference.com -- total downloads: 165\n",
      "3. 🏒 NHL Database MoneyPuckContains player data, all match data and shots data since 2007 -- total downloads: 97\n",
      "4. 🏆 National Hockey League Teams Dataset 🏒Explore an extensive dataset containing information about NHL teams. -- total downloads: 55\n",
      "5. NHL Game Data 2013-2021Data from all regular season NHL games between 2013/14 - 2021/22 inclusive -- total downloads: 22\n",
      "\n",
      "interested in any of these?\n"
     ]
    }
   ],
   "source": [
    "nhl_request = \"\"\" \n",
    "i'm looking for a dataset about players in the national hockey league. specifically i want game-level statistics for a large amount of players over\n",
    "a long period of time.\n",
    "\"\"\"\n",
    "\n",
    "nhl_embedding = embed_user_query(nhl_request)\n",
    "nhl_descriptions, nhl_metadata = find_datasets(nhl_embedding)\n",
    "nhl_reply = reply_to_user(nhl_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here's what I found:\n",
      "\n",
      "1. MLB Hitting and Pitching Stats Through All TimeUncovering History of Baseball: A Comprehensive Dataset of Hittimg and Pitching. -- total downloads: 1534\n",
      "2. 2023 MLB Player Stats2023 Major League Baseball Player Stats -- total downloads: 1389\n",
      "3. Baseball Player MetricsAnalyzing Performance Across Games, At-Bats, Runs, Hits, and More -- total downloads: 77\n",
      "4. Major League Baseball Game LogsHistorical MLB Game Logs and Player Statistics from 1871-2016 -- total downloads: 71\n",
      "5. MLB Batter Game Logs (All Players, 2023 Season)Why would I want to stand out with a snappy title. If you want this you can use. -- total downloads: 60\n",
      "\n",
      "interested in any of these?\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "mlb_request = \"\"\" \n",
    "i'm looking for a dataset about players in major league baseball. specifically i want game-level statistics for a large amount of players over\n",
    "a long period of time.\n",
    "\"\"\"\n",
    "\n",
    "interface(mlb_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here's what I found:\n",
      "\n",
      "1. Olympic Historical Dataset From Olympedia.orgEvent to Athlete level Olympic Games Results from Athens 1896 to Beijing 2022 -- total downloads: 3013\n",
      "2. Olympics Legacy: 1896-2020A Comprehensive Dataset Spanning 124 Years -- total downloads: 1472\n",
      "3. Olympics-Dataset\"Exploring Olympic Glory: A Comprehensive Dataset Unveiling the Rich History. -- total downloads: 388\n",
      "4. Olympic Athlete Performance DatasetExploring the Triumphs and Diversity of Athlete Achievements in the Olympic Game -- total downloads: 99\n",
      "5. Olympics Datasetnan -- total downloads: 44\n",
      "\n",
      "interested in any of these?\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "olympics_request = \"\"\" \n",
    "i'm looking for a dataset about olympic athletes. specifically i want event competition statistics for a large amount of athletes over\n",
    "a long period of time.\n",
    "\"\"\"\n",
    "\n",
    "interface(olympics_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# telecoms_request = \"\"\" \n",
    "\n",
    "# telecommunications usage. The dataset should include the usage date, provider ID, user ID, call duration, data usage, SMS count, service type (voice, data, SMS), location data, user demographics, and billing information. The dataset must be clean, with no missing values, consistent identifiers, accurate usage details, and provided in CSV format with clearly labeled columns and standardized date formats. Accompanying metadata describing data sources, preprocessing steps, and field definitions is required. An estimated delivery timeline and a mechanism for accessing updates, such as an API or regular data dumps, would be appreciated. The data will be used for usage pattern analysis and telecom service optimization, making accuracy and completeness critical.\n",
    "\n",
    "# \"\"\"\n",
    "# test_query = answer_users_request(telecoms_request)\n",
    "# print(test_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epl_request = \"\"\" \n",
    "# i'm looking for a dataset about players in the english premier league. specifically i want game-level statistics for a large amount of players. over\n",
    "# a long period of time.\n",
    "# \"\"\"\n",
    "\n",
    "# test_query = answer_users_request(epl_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "hey user, here's what i found:\n",
    "\n",
    "1. Title, Subtitle, summary of description\n",
    "2. Title, Subtitle, summary of description\n",
    "3. Title, Subtitle, summary of description\n",
    "\n",
    "do you want to further explore any of these?\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
